\documentclass[a4paper, 12pt, twoside]{report}

\usepackage{lipsum}

\title{Coursework Distributed Databases}
\author{
	Jens {De Staercke}
    \and
    Edouard {Goddeeris}
    \and
    Arno {Temmerman}
}



\usepackage[breakable]{tcolorbox}
\usepackage{parskip} % Stop auto-indenting (to mimic markdown behaviour)

\usepackage{iftex}
\ifPDFTeX
\usepackage[T1]{fontenc}
\usepackage{mathpazo}
\else
\usepackage{fontspec}
\fi

% Basic figure setup, for now with no caption control since it's done
% automatically by Pandoc (which extracts ![](path) syntax from Markdown).
\usepackage{graphicx}
% Maintain compatibility with old templates. Remove in nbconvert 6.0
\let\Oldincludegraphics\includegraphics
% Ensure that by default, figures have no caption (until we provide a
% proper Figure object with a Caption API and a way to capture that
% in the conversion process - todo).
\usepackage{caption}
\DeclareCaptionFormat{nocaption}{}
\captionsetup{format=nocaption,aboveskip=0pt,belowskip=0pt}

\usepackage{float}
\floatplacement{figure}{H} % forces figures to be placed at the correct location
\usepackage{xcolor} % Allow colors to be defined
\usepackage{enumerate} % Needed for markdown enumerations to work
\usepackage{geometry} % Used to adjust the document margins
\usepackage{amsmath} % Equations
\usepackage{amssymb} % Equations
\usepackage{textcomp} % defines textquotesingle
% Hack from http://tex.stackexchange.com/a/47451/13684:
\AtBeginDocument{%
	\def\PYZsq{\textquotesingle}% Upright quotes in Pygmentized code
}
\usepackage{upquote} % Upright quotes for verbatim code
\usepackage{eurosym} % defines \euro
\usepackage[mathletters]{ucs} % Extended unicode (utf-8) support
\usepackage{fancyvrb} % verbatim replacement that allows latex
\usepackage{grffile} % extends the file name processing of package graphics 
% to support a larger range
\makeatletter % fix for old versions of grffile with XeLaTeX
\@ifpackagelater{grffile}{2019/11/01}
{
	% Do nothing on new versions
}
{
	\def\Gread@@xetex#1{%
		\IfFileExists{"\Gin@base".bb}%
		{\Gread@eps{\Gin@base.bb}}%
		{\Gread@@xetex@aux#1}%
	}
}
\makeatother
\usepackage[Export]{adjustbox} % Used to constrain images to a maximum size
\adjustboxset{max size={0.9\linewidth}{0.9\paperheight}}

% The hyperref package gives us a pdf with properly built
% internal navigation ('pdf bookmarks' for the table of contents,
% internal cross-reference links, web links for URLs, etc.)
\usepackage{hyperref}
% The default LaTeX title has an obnoxious amount of whitespace. By default,
% titling removes some of it. It also provides customization options.
\usepackage{titling}
\usepackage{longtable} % longtable support required by pandoc >1.10
\usepackage{booktabs}  % table support for pandoc > 1.12.2
\usepackage[inline]{enumitem} % IRkernel/repr support (it uses the enumerate* environment)
\usepackage[normalem]{ulem} % ulem is needed to support strikethroughs (\sout)
% normalem makes italics be italics, not underlines
\usepackage{mathrsfs}



% Colors for the hyperref package
\definecolor{urlcolor}{rgb}{0,.145,.698}
\definecolor{linkcolor}{rgb}{.71,0.21,0.01}
\definecolor{citecolor}{rgb}{.12,.54,.11}

% ANSI colors
\definecolor{ansi-black}{HTML}{3E424D}
\definecolor{ansi-black-intense}{HTML}{282C36}
\definecolor{ansi-red}{HTML}{E75C58}
\definecolor{ansi-red-intense}{HTML}{B22B31}
\definecolor{ansi-green}{HTML}{00A250}
\definecolor{ansi-green-intense}{HTML}{007427}
\definecolor{ansi-yellow}{HTML}{DDB62B}
\definecolor{ansi-yellow-intense}{HTML}{B27D12}
\definecolor{ansi-blue}{HTML}{208FFB}
\definecolor{ansi-blue-intense}{HTML}{0065CA}
\definecolor{ansi-magenta}{HTML}{D160C4}
\definecolor{ansi-magenta-intense}{HTML}{A03196}
\definecolor{ansi-cyan}{HTML}{60C6C8}
\definecolor{ansi-cyan-intense}{HTML}{258F8F}
\definecolor{ansi-white}{HTML}{C5C1B4}
\definecolor{ansi-white-intense}{HTML}{A1A6B2}
\definecolor{ansi-default-inverse-fg}{HTML}{FFFFFF}
\definecolor{ansi-default-inverse-bg}{HTML}{000000}

% common color for the border for error outputs.
\definecolor{outerrorbackground}{HTML}{FFDFDF}

% commands and environments needed by pandoc snippets
% extracted from the output of `pandoc -s`
\providecommand{\tightlist}{%
	\setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\newenvironment{Shaded}{}{}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
\newcommand{\RegionMarkerTok}[1]{{#1}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
\newcommand{\NormalTok}[1]{{#1}}

% Additional commands for more recent versions of Pandoc
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{{#1}}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{{#1}}}
\newcommand{\ImportTok}[1]{{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{{#1}}}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{{#1}}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{{#1}}}
\newcommand{\BuiltInTok}[1]{{#1}}
\newcommand{\ExtensionTok}[1]{{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{{#1}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{{#1}}}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}


% Define a nice break command that doesn't care if a line doesn't already
% exist.
\def\br{\hspace*{\fill} \\* }
% Math Jax compatibility definitions
\def\gt{>}
\def\lt{<}
\let\Oldtex\TeX
\let\Oldlatex\LaTeX
\renewcommand{\TeX}{\textrm{\Oldtex}}
\renewcommand{\LaTeX}{\textrm{\Oldlatex}}
% Document parameters






% Pygments definitions
\makeatletter
\def\PY@reset{\let\PY@it=\relax \let\PY@bf=\relax%
	\let\PY@ul=\relax \let\PY@tc=\relax%
	\let\PY@bc=\relax \let\PY@ff=\relax}
\def\PY@tok#1{\csname PY@tok@#1\endcsname}
\def\PY@toks#1+{\ifx\relax#1\empty\else%
	\PY@tok{#1}\expandafter\PY@toks\fi}
\def\PY@do#1{\PY@bc{\PY@tc{\PY@ul{%
				\PY@it{\PY@bf{\PY@ff{#1}}}}}}}
\def\PY#1#2{\PY@reset\PY@toks#1+\relax+\PY@do{#2}}

\@namedef{PY@tok@w}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\@namedef{PY@tok@c}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\@namedef{PY@tok@cp}{\def\PY@tc##1{\textcolor[rgb]{0.74,0.48,0.00}{##1}}}
\@namedef{PY@tok@k}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kp}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kt}{\def\PY@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\@namedef{PY@tok@o}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@ow}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\@namedef{PY@tok@nb}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@nf}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\@namedef{PY@tok@nc}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\@namedef{PY@tok@nn}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\@namedef{PY@tok@ne}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.82,0.25,0.23}{##1}}}
\@namedef{PY@tok@nv}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@no}{\def\PY@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\@namedef{PY@tok@nl}{\def\PY@tc##1{\textcolor[rgb]{0.63,0.63,0.00}{##1}}}
\@namedef{PY@tok@ni}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.60,0.60,0.60}{##1}}}
\@namedef{PY@tok@na}{\def\PY@tc##1{\textcolor[rgb]{0.49,0.56,0.16}{##1}}}
\@namedef{PY@tok@nt}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@nd}{\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\@namedef{PY@tok@s}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@sd}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@si}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\@namedef{PY@tok@se}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.13}{##1}}}
\@namedef{PY@tok@sr}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\@namedef{PY@tok@ss}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@sx}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@m}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@gh}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\@namedef{PY@tok@gu}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\@namedef{PY@tok@gd}{\def\PY@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\@namedef{PY@tok@gi}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\@namedef{PY@tok@gr}{\def\PY@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\@namedef{PY@tok@ge}{\let\PY@it=\textit}
\@namedef{PY@tok@gs}{\let\PY@bf=\textbf}
\@namedef{PY@tok@gp}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\@namedef{PY@tok@go}{\def\PY@tc##1{\textcolor[rgb]{0.53,0.53,0.53}{##1}}}
\@namedef{PY@tok@gt}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\@namedef{PY@tok@err}{\def\PY@bc##1{{\setlength{\fboxsep}{\string -\fboxrule}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}}
\@namedef{PY@tok@kc}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kd}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kn}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kr}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@bp}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@fm}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\@namedef{PY@tok@vc}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@vg}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@vi}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@vm}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@sa}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@sb}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@sc}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@dl}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@s2}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@sh}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@s1}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@mb}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@mf}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@mh}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@mi}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@il}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@mo}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@ch}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\@namedef{PY@tok@cm}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\@namedef{PY@tok@cpf}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\@namedef{PY@tok@c1}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\@namedef{PY@tok@cs}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}

\def\PYZbs{\char`\\}
\def\PYZus{\char`\_}
\def\PYZob{\char`\{}
\def\PYZcb{\char`\}}
\def\PYZca{\char`\^}
\def\PYZam{\char`\&}
\def\PYZlt{\char`\<}
\def\PYZgt{\char`\>}
\def\PYZsh{\char`\#}
\def\PYZpc{\char`\%}
\def\PYZdl{\char`\$}
\def\PYZhy{\char`\-}
\def\PYZsq{\char`\'}
\def\PYZdq{\char`\"}
\def\PYZti{\char`\~}
% for compatibility with earlier versions
\def\PYZat{@}
\def\PYZlb{[}
\def\PYZrb{]}
\makeatother


% For linebreaks inside Verbatim environment from package fancyvrb. 
\makeatletter
\newbox\Wrappedcontinuationbox 
\newbox\Wrappedvisiblespacebox 
\newcommand*\Wrappedvisiblespace {\textcolor{red}{\textvisiblespace}} 
\newcommand*\Wrappedcontinuationsymbol {\textcolor{red}{\llap{\tiny$\m@th\hookrightarrow$}}} 
\newcommand*\Wrappedcontinuationindent {3ex } 
\newcommand*\Wrappedafterbreak {\kern\Wrappedcontinuationindent\copy\Wrappedcontinuationbox} 
% Take advantage of the already applied Pygments mark-up to insert 
% potential linebreaks for TeX processing. 
%        {, <, #, %, $, ' and ": go to next line. 
	%        _, }, ^, &, >, - and ~: stay at end of broken line. 
% Use of \textquotesingle for straight quote. 
\newcommand*\Wrappedbreaksatspecials {% 
	\def\PYGZus{\discretionary{\char`\_}{\Wrappedafterbreak}{\char`\_}}% 
	\def\PYGZob{\discretionary{}{\Wrappedafterbreak\char`\{}{\char`\{}}% 
	\def\PYGZcb{\discretionary{\char`\}}{\Wrappedafterbreak}{\char`\}}}% 
	\def\PYGZca{\discretionary{\char`\^}{\Wrappedafterbreak}{\char`\^}}% 
	\def\PYGZam{\discretionary{\char`\&}{\Wrappedafterbreak}{\char`\&}}% 
	\def\PYGZlt{\discretionary{}{\Wrappedafterbreak\char`\<}{\char`\<}}% 
	\def\PYGZgt{\discretionary{\char`\>}{\Wrappedafterbreak}{\char`\>}}% 
	\def\PYGZsh{\discretionary{}{\Wrappedafterbreak\char`\#}{\char`\#}}% 
	\def\PYGZpc{\discretionary{}{\Wrappedafterbreak\char`\%}{\char`\%}}% 
	\def\PYGZdl{\discretionary{}{\Wrappedafterbreak\char`\$}{\char`\$}}% 
	\def\PYGZhy{\discretionary{\char`\-}{\Wrappedafterbreak}{\char`\-}}% 
	\def\PYGZsq{\discretionary{}{\Wrappedafterbreak\textquotesingle}{\textquotesingle}}% 
	\def\PYGZdq{\discretionary{}{\Wrappedafterbreak\char`\"}{\char`\"}}% 
	\def\PYGZti{\discretionary{\char`\~}{\Wrappedafterbreak}{\char`\~}}% 
} 
% Some characters . , ; ? ! / are not pygmentized. 
% This macro makes them "active" and they will insert potential linebreaks 
\newcommand*\Wrappedbreaksatpunct {% 
	\lccode`\~`\.\lowercase{\def~}{\discretionary{\hbox{\char`\.}}{\Wrappedafterbreak}{\hbox{\char`\.}}}% 
	\lccode`\~`\,\lowercase{\def~}{\discretionary{\hbox{\char`\,}}{\Wrappedafterbreak}{\hbox{\char`\,}}}% 
	\lccode`\~`\;\lowercase{\def~}{\discretionary{\hbox{\char`\;}}{\Wrappedafterbreak}{\hbox{\char`\;}}}% 
	\lccode`\~`\:\lowercase{\def~}{\discretionary{\hbox{\char`\:}}{\Wrappedafterbreak}{\hbox{\char`\:}}}% 
	\lccode`\~`\?\lowercase{\def~}{\discretionary{\hbox{\char`\?}}{\Wrappedafterbreak}{\hbox{\char`\?}}}% 
	\lccode`\~`\!\lowercase{\def~}{\discretionary{\hbox{\char`\!}}{\Wrappedafterbreak}{\hbox{\char`\!}}}% 
	\lccode`\~`\/\lowercase{\def~}{\discretionary{\hbox{\char`\/}}{\Wrappedafterbreak}{\hbox{\char`\/}}}% 
	\catcode`\.\active
	\catcode`\,\active 
	\catcode`\;\active
	\catcode`\:\active
	\catcode`\?\active
	\catcode`\!\active
	\catcode`\/\active 
	\lccode`\~`\~ 	
}
\makeatother

\let\OriginalVerbatim=\Verbatim
\makeatletter
\renewcommand{\Verbatim}[1][1]{%
	%\parskip\z@skip
	\sbox\Wrappedcontinuationbox {\Wrappedcontinuationsymbol}%
	\sbox\Wrappedvisiblespacebox {\FV@SetupFont\Wrappedvisiblespace}%
	\def\FancyVerbFormatLine ##1{\hsize\linewidth
		\vtop{\raggedright\hyphenpenalty\z@\exhyphenpenalty\z@
			\doublehyphendemerits\z@\finalhyphendemerits\z@
			\strut ##1\strut}%
	}%
	% If the linebreak is at a space, the latter will be displayed as visible
	% space at end of first line, and a continuation symbol starts next line.
	% Stretch/shrink are however usually zero for typewriter font.
	\def\FV@Space {%
		\nobreak\hskip\z@ plus\fontdimen3\font minus\fontdimen4\font
		\discretionary{\copy\Wrappedvisiblespacebox}{\Wrappedafterbreak}
		{\kern\fontdimen2\font}%
	}%
	
	% Allow breaks at special characters using \PYG... macros.
	\Wrappedbreaksatspecials
	% Breaks at punctuation characters . , ; ? ! and / need catcode=\active 	
	\OriginalVerbatim[#1,codes*=\Wrappedbreaksatpunct]%
}
\makeatother

% Exact colors from NB
\definecolor{incolor}{HTML}{303F9F}
\definecolor{outcolor}{HTML}{D84315}
\definecolor{cellborder}{HTML}{CFCFCF}
\definecolor{cellbackground}{HTML}{F7F7F7}

% prompt
\makeatletter
\newcommand{\boxspacing}{\kern\kvtcb@left@rule\kern\kvtcb@boxsep}
\makeatother
\newcommand{\prompt}[4]{
	{\ttfamily\llap{{\color{#2}[#3]:\hspace{3pt}#4}}\vspace{-\baselineskip}}
}



% Prevent overflowing lines due to hard-to-break entities
\sloppy 
% Setup hyperref package
\hypersetup{
	breaklinks=true,  % so long urls are correctly broken across lines
	colorlinks=true,
	urlcolor=urlcolor,
	linkcolor=linkcolor,
	citecolor=citecolor,
}
% Slightly bigger margins than the latex defaults

\geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}




\begin{document}
\maketitle

\begin{abstract}
This is our report of the assignment for the course ``Distributed Databases''. In the following chapters we will describe how we applied the automated machine learning toolkit  \verb|auto-sklearn|  to multiple machine learning problems.
\end{abstract}

\tableofcontents

\chapter{Excercise Mammography}
As an introduction to the  \verb|auto-sklearn|  toolkit we applied it to one of the exercises given in our course. 

In the exercise Mammography we originally predicted the severity (benign/malign) of mammography results, with the use of a RandomForestClassifier. This time, however, we will be using the AutoSklearnClassifier and find out if we can get any useful predictions.

\section{Setting up the environment}
As recommended, we created a Google Colab notebook.
The installation of  \verb|auto-sklearn|  can be done with the following command:

\begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{o}{!}sudo apt\PYZhy{}get install build\PYZhy{}essential swig python3\PYZhy{}dev
\PY{o}{!}pip3 install auto\PYZhy{}sklearn
\end{Verbatim}
\end{tcolorbox}

After this, restart the runtime (Ctrl + M). You can now import the module:
\begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{import} \PY{n+nn}{autosklearn}
\PY{n}{autosklearn}\PY{o}{.}\PY{n}{\PYZus{}\PYZus{}version\PYZus{}\PYZus{}}
\end{Verbatim}
\end{tcolorbox}

\section{Importing and cleaning the data}
Importing and cleaning the data could be done in the exact same way of the original exercise, using pandas (short version):

\begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{url} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{https://raw.githubusercontent.com/HOGENT\PYZhy{}Databases/DB3\PYZhy{}Workshops/master/data/mammography.csv}\PY{l+s+s1}{\PYZsq{}}
\PY{n}{mammo} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}csv}\PY{p}{(}\PY{n}{url}\PY{p}{)}
		
\PY{c+c1}{\PYZsh{} Remove all lines that contain some “?”.}
\PY{n}{has\PYZus{}missing} \PY{o}{=} \PY{p}{(}\PY{n}{mammo} \PY{o}{==} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{?}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}\PY{o}{.}\PY{n}{astype}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{bool}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{mammo} \PY{o}{=} \PY{n}{mammo}\PY{p}{[}\PY{o}{\PYZti{}}\PY{n}{has\PYZus{}missing}\PY{p}{]}
		
\PY{c+c1}{\PYZsh{} Remove any observation that has an incorrect value in the BIRADS column.}
\PY{n}{valid\PYZus{}rows} \PY{o}{=} \PY{n}{mammo}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{BIRADS}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{isin}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{0}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{1}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{2}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{3}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{4}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{5}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
\PY{n}{mammo} \PY{o}{=} \PY{n}{mammo}\PY{p}{[}\PY{n}{valid\PYZus{}rows}\PY{p}{]}
\end{Verbatim}
\end{tcolorbox}

\begin{Verbatim}[commandchars=\\\{\}]
Shape: (820, 6)
\end{Verbatim}

\begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
	\prompt{Out}{outcolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
BIRADS Age Shape Margin Density  Severity
0       5  67     3      5       3         1
2       5  58     4      5       3         1
3       4  28     1      1       3         0
8       5  57     1      5       3         1
10      5  76     1      4       3         1
\end{Verbatim}
\end{tcolorbox}

\section{Determining a model with auto-sklearn}

First we'll seperate the features(X) from the labels(y).

\begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
	\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Step 1: Set up the required DataFrames}
\PY{n}{COLUMNS} \PY{o}{=} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Age}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Shape}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Margin}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Density}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}

\PY{n}{mammo}\PY{p}{[}\PY{n}{COLUMNS}\PY{p}{]} \PY{o}{=} \PY{n}{mammo}\PY{p}{[}\PY{n}{COLUMNS}\PY{p}{]}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{n}{pd}\PY{o}{.}\PY{n}{to\PYZus{}numeric}\PY{p}{)}

\PY{n}{X} \PY{o}{=} \PY{n}{mammo}\PY{p}{[}\PY{n}{COLUMNS}\PY{p}{]}
\PY{n}{y} \PY{o}{=} \PY{n}{mammo}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Severity}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
\end{Verbatim}
\end{tcolorbox}

\begin{Verbatim}[commandchars=\\\{\}]
X:
Age  Shape  Margin  Density
0    67      3       5        3
2    58      4       5        3
3    28      1       1        3
8    57      1       5        3
10   76      1       4        3

y:
0     1
2     1
3     0
8     1
10    1
\end{Verbatim}

Next, we'll split the data into a training, a validation and a test set.
\begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Step 2: Split the data into training, validation and test set}
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{model\PYZus{}selection} \PY{k+kn}{import} \PY{n}{train\PYZus{}test\PYZus{}split}

\PY{n}{X\PYZus{}rem}\PY{p}{,} \PY{n}{X\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}rem}\PY{p}{,} \PY{n}{y\PYZus{}test} \PY{o}{=} \PY{n}{train\PYZus{}test\PYZus{}split}\PY{p}{(}\PY{n}{X}\PY{p}{,} \PY{n}{y}\PY{p}{,} \PY{n}{test\PYZus{}size}\PY{o}{=}\PY{l+m+mf}{0.3}\PY{p}{,} \PY{n}{random\PYZus{}state}\PY{o}{=}\PY{l+m+mi}{42}\PY{p}{)}
\PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{X\PYZus{}val}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}val} \PY{o}{=} \PY{n}{train\PYZus{}test\PYZus{}split}\PY{p}{(}\PY{n}{X\PYZus{}rem}\PY{p}{,} \PY{n}{y\PYZus{}rem}\PY{p}{,} \PY{n}{test\PYZus{}size}\PY{o}{=}\PY{l+m+mf}{0.3}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

\begin{Verbatim}[commandchars=\\\{\}]
Number of training examples: 401, number of features 4
Number of validation examples: 173
Number of test examples: 246
\end{Verbatim}


Now we can build the model with the use of  \verb|auto-sklearn| . Since this is a binary classification problem (the BI-RADS data should be classified as either benign or malignant), we can make use of the AutoSklearnClassifier:
\begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Step 3. Build the classifier }
\PY{k+kn}{import} \PY{n+nn}{autosklearn}\PY{n+nn}{.}\PY{n+nn}{classification}
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{metrics} \PY{k+kn}{import} \PY{n}{accuracy\PYZus{}score}

\PY{n}{model} \PY{o}{=} \PY{n}{autosklearn}\PY{o}{.}\PY{n}{classification}\PY{o}{.}\PY{n}{AutoSklearnClassifier}\PY{p}{(}
	\PY{n}{time\PYZus{}left\PYZus{}for\PYZus{}this\PYZus{}task}\PY{o}{=}\PY{l+m+mi}{120}\PY{p}{,}
	\PY{n}{per\PYZus{}run\PYZus{}time\PYZus{}limit}\PY{o}{=}\PY{l+m+mi}{30}\PY{p}{,}
\PY{p}{)}
\PY{n}{model}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

It's very important to specify the following parameters:
\begin{itemize}
	\item \textbf{time\_left\_for\_this\_task:} time (seconds) in which  \verb|auto-sklearn|  can search for the appropriate models.
	\item \textbf{per\_run\_time\_limit:} time (seconds)  \verb|auto-sklearn|  gets for fitting the model on the training data.
\end{itemize}
Part of our job during this assesment, was to fiddle arround with these parameters, in order to get better and better models/predictions:
Ascribe large values and you increase the odds of finding a model better fitted to the (training) data. But it will take a long time to get to this model (with the risk of overfitting). 
Ascribe lower values to save time, with the risk of ending up with a bad model.

At the very beginning of this assignment, we completely forgot to specify these parameters. As a result the process took so long, that we never got it to finish. Once the paramaters were set, we received a reasonably good model right away.


We can now use the validation set to check wether or not this model can give us any reasonable predictions:
\begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Step 4. use the model on the validation set}
\PY{n}{y\PYZus{}val\PYZus{}pred} \PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}val}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Compare the predictions of the model with the actual Severity}
\PY{n}{accuracy} \PY{o}{=} \PY{n}{accuracy\PYZus{}score}\PY{p}{(}\PY{n}{y\PYZus{}val}\PY{p}{,} \PY{n}{y\PYZus{}val\PYZus{}pred}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

\begin{Verbatim}[commandchars=\\\{\}]
Accuracy of 0.8034682080924855
\end{Verbatim}

This accuracy score gives us confidence that this model is actually useful for making predictions. We feel ready to use it on the test set:
\begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
	\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Step 5. use the model on the test set}
\PY{n}{y\PYZus{}test\PYZus{}pred} \PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}test}\PY{p}{)}
		
\PY{c+c1}{\PYZsh{} Compare the predictions of the model with the actual Severity}
\PY{n}{test\PYZus{}accuracy} \PY{o}{=} \PY{n}{accuracy\PYZus{}score}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}test\PYZus{}pred}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

\begin{Verbatim}[commandchars=\\\{\}]
Estimated accuracy of the model is 0.8048780487804879
\end{Verbatim}

Our model would have correctly diagnosed about 80\% of the instances in the test set. (Which is actually better than what the random forest classifier in the original exercise could manage.)


\chapter{Kaggle competitions}
For this part of the assignment, we chose 
Investigate the models created by  \verb|auto-sklearn|  and compare them with the winning models of the Kaggle competitions.
Did you get a comparable performance?
Do you get better models if you increase the “time” budget?
What type of model is the winning model? What types of models does  \verb|auto-sklearn|  use?
Compare the required effort and required domain knowledge between the winning models and the models created by  \verb|auto-sklearn| .


!!! Kaderen dat we bij elke competition maar met 1 nieuwe variabele ``experimeteren'' brothers wright

We experimented with  \verb|auto-sklearn|  by OFAT

\clearpage

\section{Random Acts of Pizza}
\label{sec:binary-classification}

For our first competition, we looked for a binary classification problem. We found ``Random Acts of Pizza - Predicting altruism through free pizza''. ``Random Acts of Pizza'' is a community on the social network ``Reddit'', in which users can post a [REQUEST] for free pizza. At that point, other users are free to send this person the gift. If a good samaritan did decide to send pizza, the original user wil post a [THANKS] message.

\begin{figure}
	\includegraphics[width=\textwidth]{img/pizzas.png}
\end{figure}

Our job was to predict whether or not a users received free pizza, based on the information surrounding the [REQUEST] post.

\subsection{Importing the Data}
Importing the data is analogous for every Kaggle competition. Just run the command specified under the ``Data'' tab of the competition. This will download the dataset using the Kaggle API:

\begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{o}{!}kaggle competitions download \PYZhy{}c random\PYZhy{}acts\PYZhy{}of\PYZhy{}pizza
\end{Verbatim}
\end{tcolorbox}

For this competition we simply had to unzip these files and out came a .json file for the training and the test set. After that, the data can be brought into a pandas DataFrame:

\begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{df\PYZus{}train} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}json}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{/content/train.json}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

\subsection{Data preparation}
We quickly realised that the test set contained less features than the training set. This is because the training set contained data about the reddit posts on retrieval (of pizza). It is self evident that this data is not specified in the test set, since this is exactly what we have to predict. 
In general, we had to get rid of all the columns that were only present in the training set. Namely, there is no use for a model with 31 features, if the test set can only supply us with 17.

\begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Remove data regarding retrieval}
\PY{n}{retrieval\PYZus{}cols} \PY{o}{=} \PY{n}{df\PYZus{}train}\PY{o}{.}\PY{n}{filter}\PY{p}{(}\PY{n}{regex}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{.*\PYZus{}at\PYZus{}retrieval}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{df\PYZus{}train} \PY{o}{=} \PY{n}{df\PYZus{}train}\PY{o}{.}\PY{n}{drop}\PY{p}{(}\PY{n}{columns}\PY{o}{=}\PY{n}{retrieval\PYZus{}cols}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Remove the edit unaware request text}
\PY{n}{df\PYZus{}train} \PY{o}{=} {df\PYZus{}train}\PY{o}{.}\PY{n}{drop}\PY{p}{(}\PY{n}{columns}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{request\PYZus{}text}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Remove other uncommon columns}
\PY{n}{df\PYZus{}train} \PY{o}{=} {df\PYZus{}train}\PY{o}{.}\PY{n}{drop}\PY{p}{(}\PY{n}{columns}\PY{o}{=}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{post\PYZus{}was\PYZus{}edited}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{requester\PYZus{}user\PYZus{}flair}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

Both data sets came with two timestamps. We picked the UTC variant, as we don't need both of them in the model. An additional timestamp wouldn't be a useful feature, because it doesn't bring any new information.

\begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Remove redundant timestamp}
\PY{n}{df\PYZus{}train} \PY{o}{=} {df\PYZus{}train}\PY{o}{.}\PY{n}{drop}\PY{p}{(}\PY{n}{columns}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{unix\PYZus{}timestamp\PYZus{}of\PYZus{}request}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{df\PYZus{}train} \PY{o}{=} {df\PYZus{}test}\PY{o}{.}\PY{n}{drop}\PY{p}{(}\PY{n}{columns}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{unix\PYZus{}timestamp\PYZus{}of\PYZus{}request}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

In order to fit the model to them, the labels requester\_received\_pizza had to be cast to a numeric type.

\begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{requester\PYZus{}received\PYZus{}pizza}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{requester\PYZus{}received\PYZus{}pizza}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{astype}\PY{p}{(}\PY{n+nb}{int}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

\subsection{Feature Selection}
Now the data was prepared, we could decide on which columns were to be used as features. These are some of the most notable decisions made in this step:

\begin{itemize}
	\item Self evidently, column \PY{l+s+s1}{requester\PYZus{}subreddits} (list of subreddits) couldn't directly be used as a feature. Instead, we used it to make out whether or not the requester is a member of the ``Random Acts of Pizza'' subreddit using the function \PY{n+nf}{reduce\PYZus{}subreddits\PYZus{}to\PYZus{}membership}\PY{p}{(}\PY{n}{df}\PY{p}{)}.
 	\item We noticed something odd about the datasets. Both the training and the test set contained a column \PY{l+s+s1}{giver\PYZus{}username\PYZus{}if\PYZus{}known}. This is strange, considering that the fact if a pizza was given or not, is exactly what has to be predicted. For a moment, we thought we caught a leakage feature  But a quick look at the data revealed that most of the values were "N/A". We could, however, still use the ``missingness'' of this variable as a feature. A post with a known giver, will certainly have received a pizza. We did transformed it to a int column with 0 or 1 values to signify if a giver was mentioned.
\end{itemize}

Eventually, our first model was built using the following features:
\begin{Verbatim}[commandchars=\\\{\}]
Data columns (total 14 columns):
\#   Column                                  Non-Null Count  Dtype
---  ------                                  --------------  -----
0   giver_username_if_known                  4040 non-null   int64  
1   requester_account_age_in_days            4040 non-null   float64
2   requester_days_since_first_post_on_raop  4040 non-null   float64
3   requester_number_of_comments             4040 non-null   int64  
4   requester_number_of_comments_in_raop     4040 non-null   int64  
5   requester_number_of_posts                4040 non-null   int64  
6   requester_number_of_posts_on_raop        4040 non-null   int64  
7   requester_number_of_subreddits           4040 non-null   int64  
8   requester_upvotes_minus_downvotes        4040 non-null   int64  
9   requester_upvotes_plus_downvotes         4040 non-null   int64  
10  unix_timestamp_of_request_utc            4040 non-null   int64  
11  requester_member_of_raop                 4040 non-null   int64  
\end{Verbatim}

At the end the end of this exercise we did some further experimentation with the features.

\subsection{Binary classification with auto-sklearn}
Contrary to the exericises that we made in the course, the data was already split up into a training and a test set. This is, of course, because the actual output values for the test set have to be inaccessible.
However, we did have to split up the training set into a (smaller) training and a validation set. Otherwise, there'd be no way for us to check the generated models before we submit our predictions for the test set.

\begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{X\PYZus{}val}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}val} \PY{o}{=} \PY{n}{train\PYZus{}test\PYZus{}split}\PY{p}{(}\PY{n}{X}\PY{p}{,} \PY{n}{y}\PY{p}{,} \PY{n}{test\PYZus{}size}\PY{o}{=}\PY{l+m+mf}{0.3}\PY{p}{,} \PY{n}{random\PYZus{}state}\PY{o}{=}\PY{l+m+mi}{42}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

Because this is a binary classificaton problem (pizza requesters should be classed on wether or not ther received pizza) we can use the AutoSklearnClassifier:
\begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{import} \PY{n+nn}{autosklearn}\PY{n+nn}{.}\PY{n+nn}{classification}

\PY{n}{model} \PY{o}{=} \PY{n}{autosklearn}\PY{o}{.}\PY{n}{classification}\PY{o}{.}\PY{n}{AutoSklearnClassifier}\PY{p}{(}
	\PY{n}{per\PYZus{}run\PYZus{}time\PYZus{}limit}\PY{o}{=}\PY{l+m+mi}{30}\PY{p}{,}
	\PY{n}{time\PYZus{}left\PYZus{}for\PYZus{}this\PYZus{}task}\PY{o}{=}\PY{l+m+mi}{120}\PY{p}{,}
\PY{p}{)}
\PY{n}{model}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

To model was automatically made and fit to the training set labels.

\subsection{Making Predictions}

First we used the model on the validation set:
\begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{y\PYZus{}val\PYZus{}pred} \PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}val}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

It made predictions with an accuracy of roughly 83\%.

We decided to make the predictions with the test data. After submitting we received a score of 64\%.


At first, this seemed like a serious drop in accuracy to us. To investigate this we made the confusion matrix of the validation predictions. They showed a high true negative rate (99\%), but a fairly low true positive rate (38\%). In other words, our model is very good at saying ``no''. It is, in fact, a bit ``too good'' at saying ``no''. This explains the score of 64\% which is based on the Receiver Operating Curve (created by plotting the TPR against the FPR). It's not the same as an accuracy of 64\%.

This score placed us in the top 35\% on the leaderboard. We were pleasantly surprised by this, given that this was our first attempt at a Kaggle course.

It's worth noting that auto-sklearn was able to figure out that all posts with a \PY{l+s+s1}{giver\PYZus{}username\PYZus{}if\PYZus{}known} equal to 1 should receive a positive label (received pizza).

\subsection{Comparison with the Winning Model}

\subsection{Further Experimentation}
In this first Kaggle competition, we decided to experiment with the features to find out if  \verb|auto-sklearn|  would return a better model. We tried including/excluding different features.






\begin{itemize}
	\item Consider features \PY{l+s+s1}{requester\PYZus{}upvotes\PYZus{}plus\PYZus{}downvotes}\PY{l+s+s1}{\PYZsq{}} and \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{requester\PYZus{}upvotes\PYZus{}minus\PYZus{}downvotes}: We wondered if it would make a difference to our model if we seperated the upvotes and downvotes into their own seperate features. Namely, in the current model, there is no way of ``adding weight'' to the upvotes, without also doing this to the downvotes and vice versa. We wrote function \PY{n+nf}{calculate\PYZus{}upvotes\PYZus{}and\PYZus{}downvotes}\PY{p}{(}\PY{n}{df}\PY{p}{)} for making this seperation. Unfortunately, this made a negligible improvent to our final score.
	
	\item Posts in the RAOP subreddit are indicated as a request by placing ``[REQUEST]'' in the title.  We created a feature to distinguish valid requests from other posts using this function: \PY{n+nf}{map\PYZus{}title\PYZus{}to\PYZus{}validity}\PY{p}{(}\PY{n}{df}\PY{p}{)}. Again, this made very little improvement to the final predictions.
	
	\item The next feature demanded a bit of domain knowledge: the rules of RAOP state that a reddit account should be at least 90 days old to qualify for making a valid request. Some users try with an account that's younger, but they're not very succesful. We made and additional feature, signifying if an account is old enough to qualify for pizza. Again, the experiment didn't pay off.
\end{itemize}

One could argue that \verb|auto-sklearn| is pretty succesful at determining the underlying importances of features for given data. This could be the reason that our manual attempts at creating additional features were insignificant.

This is a list of the features that made it in the final model:

\begin{Verbatim}[commandchars=\\\{\}]
Data columns (total 14 columns):
\#   Column                                   Non-Null Count  Dtype
---  ------                                   --------------  -----
0   giver\_username\_if\_known                  4040 non-null   int64
1   requester\_account\_age\_in\_days            4040 non-null   float64
2   requester\_days\_since\_first\_post\_on\_raop  4040 non-null   float64
3   requester\_number\_of\_comments             4040 non-null   int64
4   requester\_number\_of\_comments\_in\_raop     4040 non-null   int64
5   requester\_number\_of\_posts                4040 non-null   int64
6   requester\_number\_of\_posts\_on\_raop        4040 non-null   int64
7   requester\_number\_of\_subreddits           4040 non-null   int64
8   unix\_timestamp\_of\_request\_utc            4040 non-null   int64
9   requester\_member\_of\_raop                 4040 non-null   int64
10  requester\_upvotes                        4040 non-null   int64
11  requester\_downvotes                      4040 non-null   int64
12  valid\_request\_title                      4040 non-null   int64
13  requester\_account\_old\_enough             4040 non-null   int64
\end{Verbatim}


\clearpage

\section{Forest Cover Type Prediction}
\label{sec:multiclass-classification}
Forest cover type prediction\\
Abstract classification

\subsection{Importing and cleaning the data}

\subsection{Multiclass classification with auto-sklearn}

\subsection{Making predictions}

\subsection{Further Experimentation}
fiddle arround with parameters


\clearpage

\section{House Prices}
\label{sec:regression}
House prices

\subsection{Importing and cleaning the data}

\subsection{Regression with auto-sklearn}

\subsection{Making predictions}

\subsection{Experimentation}
more or less features => binarizer/onehotencoder

\end{document}
